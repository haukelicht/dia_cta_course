{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e627b53",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a5f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can ignore this cell\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f662ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if on colab\n",
    "COLAB = True\n",
    "try:\n",
    "    import google.colab\n",
    "except:\n",
    "    COLAB=False\n",
    "\n",
    "if COLAB:\n",
    "    !pip install -q umap-learn~=0.5.9.post2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68986da0",
   "metadata": {},
   "source": [
    "Load the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3aa057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70fbcc",
   "metadata": {},
   "source": [
    "## Load and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7e9a3",
   "metadata": {},
   "source": [
    "Let's use the data from Fornaciari et al. ([2021](https://doi.org/10.18653/v1/2021.findings-acl.301)).\n",
    "This dataset contains (English-language) party manifestos sentences.\n",
    "Each sentence is labeled as either a pledge or not a pledge.\n",
    "The data was labeled applying Fornaciari Thomson et al.'s' ([2017](https://doi.org/10.1111/ajps.12313), 532) definition: \n",
    "\n",
    "> [A pledge is] a statement committing a party to one specific action or outcome that can be clearly determined to have occurred or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775f303",
   "metadata": {},
   "source": [
    "Define the path to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1baec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"..\", \"..\", \"..\")\n",
    "data_path = base_path / \"data\" / \"labeled\" / \"fornaciari_we_2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a0587",
   "metadata": {},
   "source": [
    "Define the file path and (down)load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3bef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = data_path / \"fornaciari_we_2021-pledge_binary.tsv\"\n",
    "if not fp.exists():\n",
    "    # download the data if not present yet\n",
    "    url = \"https://cta-text-datasets.s3.eu-central-1.amazonaws.com/labeled/fornaciari_we_2021/fornaciari_we_2021-pledge_binary.tsv\"\n",
    "    df = pd.read_csv(url, encoding = \"ISO-8859-1\")\n",
    "    fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(fp, index=False, encoding = \"ISO-8859-1\")\n",
    "\n",
    "df = pd.read_csv(fp, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfcd21c",
   "metadata": {},
   "source": [
    "Let's inspect the data set by looking at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0867126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>metadata__party</th>\n",
       "      <th>metadata__year</th>\n",
       "      <th>metadata__split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>At the same time, corruption, scams and crime ...</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2014</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There has been gross misuse and total denigrat...</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2014</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>There has also been erosion of authority of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2014</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  label  \\\n",
       "0        1  At the same time, corruption, scams and crime ...      0   \n",
       "1        2  There has been gross misuse and total denigrat...      0   \n",
       "2        3  There has also been erosion of authority of th...      0   \n",
       "\n",
       "  metadata__party  metadata__year metadata__split  \n",
       "0             BJP            2014             trn  \n",
       "1             BJP            2014             trn  \n",
       "2             BJP            2014             trn  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f324b9bd",
   "metadata": {},
   "source": [
    "As you can see, it records the sentence, its label, and some metadata.\n",
    "\n",
    "The labels are distributed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842ccf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4246\n",
       "1    1417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f5ea7",
   "metadata": {},
   "source": [
    "These numbers indicate \n",
    "\n",
    "- `1`: pledge\n",
    "- `0`: not a pledge\n",
    "\n",
    "So lets capture this is in a dictionary that maps label classes' names to their numeric IDs and _vice versa_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b43182",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"no pledge\", 1: \"pledge\"}\n",
    "label2id = {\"no pledge\": 0, \"pledge\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ee426",
   "metadata": {},
   "source": [
    "One important aspect of the metadata is the column `metadata__split`.\n",
    "\n",
    "It indicates that the sentences in the dataset have already been split into two \"splits\": A training (`trn`) and a development (`dev`) split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d4c61e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metadata__split\n",
       "trn    5089\n",
       "dev     574\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metadata__split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562f53a",
   "metadata": {},
   "source": [
    "We will use the dev split as a \"test\" set for evaluating its performance after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c3fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['metadata__split']=='dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0dfc57",
   "metadata": {},
   "source": [
    "But for effective training, we will need an additional valdiation set (discussed further below).\n",
    "So we will sample 10% of the examples in the original training into a \"validation\" split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da77c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['metadata__split']=='trn']\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1, stratify=df_train['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2a524",
   "metadata": {},
   "source": [
    "Now, we also keep only the columns relevant for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f541195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['text', 'label']\n",
    "df_train = df_train[cols].rename(columns={'text':'text', 'label':'labels'})\n",
    "df_val = df_val[cols].rename(columns={'text':'text', 'label':'labels'})\n",
    "df_test = df_test[cols].rename(columns={'text':'text', 'label':'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8283cf7",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f89f1",
   "metadata": {},
   "source": [
    "In the era of large pre-trained language models, fine-tuning has become a crucial step in adapting these models to specific tasks and datasets.\n",
    "\n",
    "**Fine-tuning** means taking a pre-trained model and training it further on a smaller, task-specific dataset. \n",
    "\n",
    "The key idea is that:\n",
    "\n",
    "1. the pre-trained model has already learned a wealth of linguistic knowledge from vast amounts of text data, and \n",
    "2. by fine-tuning it on a specific task, we can adapt this knowledge to perform well on this task. \n",
    "\n",
    "In essence, fine-tuning allows us to harness a model's pre-trained capabilities while also learning the nuances of the new task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79b3f8",
   "metadata": {},
   "source": [
    "We will proceed in the three steps:\n",
    "\n",
    "1. Prepare training: \n",
    "    - specify (additional) classification performance metrics to compute when evaluating the model\n",
    "    - Define training arguments that control the fine-tuning process\n",
    "    - Create the classification model\n",
    "2. Fine-tune the model on the training data (`df_train`) while monitoring its performance using the validation data (`df_val`)\n",
    "3. Evaluate the fine-tuned model on the test data (`df_test`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff03b96",
   "metadata": {},
   "source": [
    "### Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a7084",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb584c3",
   "metadata": {},
   "source": [
    "By default, `simpletransformers` always computes the Mathew's correlation coefficient (MCC) during evaluation for classification tasks.\n",
    "\n",
    "But we want to monitor additional metrics as well.\n",
    "So let's define them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26021a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "extra_metrics_to_compute = dict(\n",
    "    precision=precision_score,\n",
    "    recall=recall_score,\n",
    "    f1=f1_score, \n",
    "    ba=balanced_accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c6510",
   "metadata": {},
   "source": [
    "Here is what these metrics mean:\n",
    "\n",
    "- The **precision** is the share of true positive predictions among all positive predictions made by the model.\n",
    "    So it tells us in how many of the examples the model labeled as positive instance (here, pledge instances) it was actually correct.\n",
    "\n",
    "- The **recall** is the share of actual positive examples that were correctly identified by the model.\n",
    "    So it tells us how many of all actual pledge instances the model was able to find.\n",
    "\n",
    "- The **F1 score** combines these metrics into a single value by calculating their harmonic mean.\n",
    "    It thus provides a balanced summary of precision and recall.\n",
    "\n",
    "- The **balanced accuracy** is the average of recall obtained on each class.\n",
    "    So it accounts for class imbalance by giving equal weight to the performance on both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ac593",
   "metadata": {},
   "source": [
    "#### The training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75ed53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "train_args = ClassificationArgs(\n",
    "    \n",
    "    # define a folder (relative to current working directory) to store outputs\n",
    "    output_dir=\"outputs/\",\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # main hyperparameters\n",
    "    num_train_epochs = 5,  # how many times to iterate over the entire training set\n",
    "    train_batch_size = 16, # how many examples per batch to use during training\n",
    "    \n",
    "    # switch on evaluation during training\n",
    "    evaluate_during_training = True,\n",
    "    # NOTE \n",
    "    #  Evaluation means that the model will be applied to held-out data (\"validation\" examples).\n",
    "    #  These examples will be provided below when calling `model.train_model()` method by passing \n",
    "    #   our `df_val` data frame to this methods`eval_df` argument.\n",
    "    #  Based on the examples in these validation examples, we will be able to monitor the model's \n",
    "    #   classification performance (e.g. accuracy, f1, etc.) and how it changes during training.\n",
    "    #  Using held-out data, that is, data that is not used to train the model, allows use to \n",
    "    #   compute a realistic estimate of model performance on \"unseen\" data.\n",
    "    \n",
    "    # Let's define some parameters relevant for evaluation:\n",
    "    evaluate_during_training_steps = 50, # evaluate model after every 50 training steps\n",
    "    eval_batch_size = 32, # number of examples per batch to use during evaluation\n",
    "    evaluate_each_epoch = False, # switch off evaluation at the end of each epoch\n",
    "    \n",
    "    \n",
    "    # switch on early stopping\n",
    "    use_early_stopping = True,\n",
    "    # NOTE: We use early stopping to avoid overfitting of the model to the  training examples.\n",
    "    #  Overfitting means that the model learns to classify the training examples very well \n",
    "    #   but at the detriment of its ability to generalize to \"unseen\" (i.e., held-out) data.\n",
    "    #  With early stopping means to take monitor the model's performance on validation examples\n",
    "    #   during training (as specified above), and stop training when the performance on the\n",
    "    #   validation examples stops improving.\n",
    "    early_stopping_metric = \"f1\", # what metric to monitor for early stopping?\n",
    "    early_stopping_delta = 0.015, # how much must this metric improve to be considered an improvement\n",
    "    early_stopping_metric_minimize = False, # does \"impriovement\" mean that the metric should decrease?\n",
    "    early_stopping_patience = 5, # how many evaluation steps to wait for improvement before stopping training?\n",
    "\n",
    "    manual_seed = 42,\n",
    "    \n",
    "    # finally, overwrite some of the default arguments defined by the ClassificationArgs\n",
    "    no_save = True, # do not save model after training\n",
    "    save_eval_checkpoints = False, # do not save model checkpoints during evaluation\n",
    "    save_model_every_epoch = False, # do not save model after each epoch\n",
    "    no_cache = True, # do not cache data\n",
    "    use_multiprocessing = False, # do not use multiprocessing for data loading\n",
    "    use_multiprocessing_for_evaluation = False, # do not use multiprocessing for evaluation data loading\n",
    "    fp16 = False # do not use mixed precision training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db4c4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute inverse-proportional class weights\n",
    "cnts = df_train['labels'].value_counts()\n",
    "class_weights = cnts.sum()/cnts\n",
    "class_weights /= class_weights.sum()\n",
    "class_weights = class_weights.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2b0d5",
   "metadata": {},
   "source": [
    "Now we are ready to create our classifier by \n",
    "\n",
    "1. specifying the type and name of the model we want to fine-tune\n",
    "2. passing the training arguments define above\n",
    "3. specifying the number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da73600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "classifier = ClassificationModel(\n",
    "    model_type=\"roberta\",\n",
    "    model_name=model_name,\n",
    "    args=train_args,\n",
    "    num_labels=len(id2label),\n",
    "    weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0d5bd",
   "metadata": {},
   "source": [
    "**_Note:_** executing the above cell will raise a _warning_ message reading:\n",
    "\n",
    "```\n",
    "Some weights ... were not initialized from ...\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "```\n",
    "\n",
    "This is expected behavior âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e19e8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hauke-licht/miniforge/envs/dia_cta_course/lib/python3.12/site-packages/simpletransformers/classification/classification_model.py:544: UserWarning: The 'eval_df' parameter has been deprecated and will be removed in a future version. Please use 'eval_data' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354f28cacdab4af8a82b98c7b2409081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc24570fc1c42c7be8dd4779a9dd648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7cb289cad94a85a67ac9af67694c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2229709f6b59459b843c6164c7718d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d69070123242b4a4a4e69fbcbd9218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd680481d7c47b4bf107c1233cb5a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8305653a239a46da93bf9138b7241e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9d0a75b2424aa39109784c2db2c254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c566eab8a2bf433bb64f3a557665f613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069fa77cf7be4f87bcd96d174f4b1575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5013407d54448b7a8873b5985bf927f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bee374e98444e91977ef86d0f2c07e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c152b083592c4b0dbef74b254c6bd7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f62b86727904afb836a999e84d5d33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a866fcec2094011968d6a3bf30be442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc2496fabb6451f93d3f0ab48ac9c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2b20356b444816893856211b75853c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f6635a1d704609b653a308e2d74657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39538bae5d9e4495b0232dbd76bbf6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05be802d73584993a54e66e64acd5f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961c30c39087446b940a84603b1cfb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps, results = classifier.train_model(df_train.head(3_000), eval_df=df_val.head(250), **extra_metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc204d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ba</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.607441</td>\n",
       "      <td>0.500813</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.721589</td>\n",
       "      <td>55</td>\n",
       "      <td>132</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>0.843330</td>\n",
       "      <td>0.557808</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.784526</td>\n",
       "      <td>0.480244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.353002</td>\n",
       "      <td>0.507536</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.740808</td>\n",
       "      <td>31</td>\n",
       "      <td>176</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.843246</td>\n",
       "      <td>0.693335</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.715306</td>\n",
       "      <td>0.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>1.121513</td>\n",
       "      <td>0.445592</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.636028</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0.868196</td>\n",
       "      <td>0.651725</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.582160</td>\n",
       "      <td>0.750504</td>\n",
       "      <td>0.639333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.480991</td>\n",
       "      <td>0.572352</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.779254</td>\n",
       "      <td>51</td>\n",
       "      <td>153</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>0.879872</td>\n",
       "      <td>0.674425</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.809728</td>\n",
       "      <td>0.507210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.461299</td>\n",
       "      <td>0.532289</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.752863</td>\n",
       "      <td>32</td>\n",
       "      <td>177</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.860131</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.598129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>0.507175</td>\n",
       "      <td>0.562249</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.774196</td>\n",
       "      <td>36</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0.875840</td>\n",
       "      <td>0.727406</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.751680</td>\n",
       "      <td>0.514670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350</td>\n",
       "      <td>0.450001</td>\n",
       "      <td>0.546176</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.773068</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.858283</td>\n",
       "      <td>0.729485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.771673</td>\n",
       "      <td>0.498372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>0.547252</td>\n",
       "      <td>0.491874</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.739457</td>\n",
       "      <td>33</td>\n",
       "      <td>172</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.863827</td>\n",
       "      <td>0.717999</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.720178</td>\n",
       "      <td>0.625993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>450</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>0.596019</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.795731</td>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>0.889113</td>\n",
       "      <td>0.759396</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.812920</td>\n",
       "      <td>0.537160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.567346</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>38</td>\n",
       "      <td>173</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>0.867776</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.660870</td>\n",
       "      <td>0.761929</td>\n",
       "      <td>0.836609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>550</td>\n",
       "      <td>0.190258</td>\n",
       "      <td>0.573495</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.784953</td>\n",
       "      <td>40</td>\n",
       "      <td>171</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>0.878108</td>\n",
       "      <td>0.749848</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>0.546245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.586171</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>41</td>\n",
       "      <td>171</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0.881552</td>\n",
       "      <td>0.743503</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.779990</td>\n",
       "      <td>1.014012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>650</td>\n",
       "      <td>0.231825</td>\n",
       "      <td>0.554530</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.777184</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0.869288</td>\n",
       "      <td>0.728692</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.774362</td>\n",
       "      <td>0.796031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>700</td>\n",
       "      <td>0.706929</td>\n",
       "      <td>0.554509</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.772748</td>\n",
       "      <td>37</td>\n",
       "      <td>173</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>0.863323</td>\n",
       "      <td>0.693240</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.754116</td>\n",
       "      <td>1.185334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>750</td>\n",
       "      <td>0.436951</td>\n",
       "      <td>0.585092</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.784891</td>\n",
       "      <td>52</td>\n",
       "      <td>153</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>0.884661</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.817540</td>\n",
       "      <td>0.669531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_step  train_loss       mcc  accuracy  f1_score  tp   tn  fp  fn  \\\n",
       "0            50    0.607441  0.500813     0.748  0.721589  55  132  54   9   \n",
       "1           100    0.353002  0.507536     0.828  0.740808  31  176  10  33   \n",
       "2           150    1.121513  0.445592     0.644  0.636028  62   99  87   2   \n",
       "3           200    0.480991  0.572352     0.816  0.779254  51  153  33  13   \n",
       "4           250    0.461299  0.532289     0.836  0.752863  32  177   9  32   \n",
       "5           300    0.507175  0.562249     0.844  0.774196  36  175  11  28   \n",
       "6           350    0.450001  0.546176     0.828  0.773068  42  165  21  22   \n",
       "7           400    0.547252  0.491874     0.820  0.739457  33  172  14  31   \n",
       "8           450    0.158072  0.596019     0.836  0.795731  49  160  26  15   \n",
       "9           500    0.023891  0.567346     0.844  0.779785  38  173  13  26   \n",
       "10          550    0.190258  0.573495     0.844  0.784953  40  171  15  24   \n",
       "11          600    0.005686  0.586171     0.848  0.791667  41  171  15  23   \n",
       "12          650    0.231825  0.554530     0.832  0.777184  42  166  20  22   \n",
       "13          700    0.706929  0.554509     0.840  0.772748  37  173  13  27   \n",
       "14          750    0.436951  0.585092     0.820  0.784891  52  153  33  12   \n",
       "\n",
       "       auroc     auprc  precision    recall        f1        ba  eval_loss  \n",
       "0   0.843330  0.557808   0.504587  0.859375  0.635838  0.784526   0.480244  \n",
       "1   0.843246  0.693335   0.756098  0.484375  0.590476  0.715306   0.638300  \n",
       "2   0.868196  0.651725   0.416107  0.968750  0.582160  0.750504   0.639333  \n",
       "3   0.879872  0.674425   0.607143  0.796875  0.689189  0.809728   0.507210  \n",
       "4   0.860131  0.713904   0.780488  0.500000  0.609524  0.725806   0.598129  \n",
       "5   0.875840  0.727406   0.765957  0.562500  0.648649  0.751680   0.514670  \n",
       "6   0.858283  0.729485   0.666667  0.656250  0.661417  0.771673   0.498372  \n",
       "7   0.863827  0.717999   0.702128  0.515625  0.594595  0.720178   0.625993  \n",
       "8   0.889113  0.759396   0.653333  0.765625  0.705036  0.812920   0.537160  \n",
       "9   0.867776  0.706208   0.745098  0.593750  0.660870  0.761929   0.836609  \n",
       "10  0.878108  0.749848   0.727273  0.625000  0.672269  0.772177   0.546245  \n",
       "11  0.881552  0.743503   0.732143  0.640625  0.683333  0.779990   1.014012  \n",
       "12  0.869288  0.728692   0.677419  0.656250  0.666667  0.774362   0.796031  \n",
       "13  0.863323  0.693240   0.740000  0.578125  0.649123  0.754116   1.185334  \n",
       "14  0.884661  0.692069   0.611765  0.812500  0.697987  0.817540   0.669531  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3586965c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c1694125cd47e3b24a24f621514921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787a53b987fe48f0961ede0a5a27ac7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_res, probs, *_ = classifier.eval_model(df_test, **extra_metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(eval_res, index=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b6bff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model_path = base_path / \"models\" / (model_name + \"-pledge-binary\")\n",
    "classifier.args.no_save = False\n",
    "classifier.save_model(output_dir=model_path, model=classifier.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "285117f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "import shutil\n",
    "shutil.rmtree(\"outputs/\", ignore_errors=True)\n",
    "shutil.rmtree(\"runs/\", ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dia_cta_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
